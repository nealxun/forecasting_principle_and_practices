#Forecasting hierarchical or grouped time series {#ch-hierarchical}

*Warning: this is a more advanced section and assumes knowledge of some basic matrix algebra. We have however tried to simplify and explain in as much as detail as possible all the notation used.*

## Hierarchical time series

Time series can often be naturally disaggregated in a hierarchical structure using attributes such as geographical location, product type, etc. For example, the total number of bicycles sold by a cycling warehouse can be disaggregated into a hierarchy of bicycle types. Such a warehouse will sell road bikes, mountain bikes, children bikes or hybrids. Each of these can be disaggregated into finer categories. Children’s bikes can be divided into balance bikes for children under 4 years old, single speed bikes for children between 4 and 6 and bikes for children over the age of 6. Hybrid bikes can be divided into city, commuting, comfort, and trekking bikes; and so on. Such disaggregation imposes a hierarchical structure. We refer to these as *hierarchical time series*.

To take another example, a manufacturing company may track sales by country, and within each country by region, and within each region by sales outlet. Such geographical structures are commonly found in business, economics and other areas. Again, this is a hierarchical structure, and the complete collection of sales data can be thought of as hierarchical time series. An important feature of hierarchical time series is that they have a unique structure with which they disaggregate or aggregate.

Figure \@ref(fig:HierTree) below shows a $K=2$-level hierarchical structure.^[We will use this hierarchical structure in order to introduce the methods for forecasting hierarchical time series that follow.] At the top of the hierarchy, level 0, is the "Total", the most aggregate level of the data. We denote as $y_t$ the $t$th observation of the "Total" series for $t=1,\dots,T$.

The "Total" is disaggregated into 2 series at level 1 and each of these into 3 and 2 series respectively at the bottom level of the hierarchy, level 2. Below the top most aggregate level we denote as $\y{j}{t}$ the $t$th observation of the series which corresponds to node $j$. For example $y_{A,t}$ denotes the $t$th observation of the series corresponding to node A at level 1, $y_{AB,t}$ denotes the $t$th observation of the series corresponding to node AB at level 2, and so on.

The Total number of series in a hierarchy is given by $n=1+n_1+\dots+n_K$ where $n_i$ is the number of series at level $i$ of the hierarchy. In this case $n=1+2+5=8$.

```{r HierTree, echo=FALSE, fig.cap="A two level hierarchical tree diagram.", message=FALSE, warning=FALSE, cache=TRUE, fig.show = "hold",fig.height=8,fig.width=12}

g <- igraph::graph_from_literal(Total--A:B, A--AA:AB:AC, B--BA:BB)
layout <- igraph::layout_as_tree(g, root = "Total")
igraph::V(g)$color <- c("Thistle", "GreenYellow", "LightBlue",
  rep("GreenYellow", 3), rep("LightBlue", 2))
igraph::V(g)$label.cex<-2

plot(g, layout = layout,vertex.size=40)
```

For any time $t$, the observations at the bottom level of the structure will aggregate to the observations of the series above. For example,
\begin{equation}
y_{t}=\y{AA}{t}+\y{AB}{t}+\y{AC}{t}+\y{BA}{t}+\y{BB}{t}
  (\#eq:toplevel)
\end{equation} and
\begin{equation} \y{A}{t}=\y{AA}{t}+\y{AB}{t}+\y{AC}{t}\quad \text{and} \quad  \y{B}{t}=\y{BA}{t}+\y{BB}{t}.
(\#eq:middlelevel)
\end{equation}
Substituting \@ref(eq:middlelevel) into \@ref(eq:toplevel) we also get $y_{t}=\y{A}{t}+\y{B}{t}$. These can be thought of as aggregation constraints or summing equalities and can be effectively represented using matrix notation. We construct an $n\times n_K$ matrix referred to as the "summing" matrix $\bm{S}$ which dictates how the bottom level series are aggregated, consistent with the structure. For the structure in Figure \@ref(fig:HierTree) we can write
$$
  \begin{bmatrix}
    y_{t} \\
    \y{A}{t} \\
    \y{B}{t} \\
    \y{AA}{t} \\
    \y{AB}{t} \\
    \y{AC}{t} \\
    \y{BA}{t} \\
    \y{BB}{t}
  \end{bmatrix}
  =
  \begin{bmatrix}
    1 & 1 & 1 & 1 & 1 \\
    1 & 1 & 1 & 0 & 0 \\
    0 & 0 & 0 & 1 & 1 \\
    1  & 0  & 0  & 0  & 0  \\
    0  & 1  & 0  & 0  & 0  \\
    0  & 0  & 1  & 0  & 0  \\
    0  & 0  & 0  & 1  & 0  \\
    0  & 0  & 0  & 0  & 1
  \end{bmatrix}
  \begin{bmatrix}
    \y{AA}{t} \\
    \y{AB}{t} \\
    \y{AC}{t} \\
    \y{BA}{t} \\
    \y{BB}{t}
  \end{bmatrix}
$$
or in more compact notation
$$
  \bm{y}_t=\bm{S}\bm{y}_{K,t},
$$
where $\bm{y}_t$ is a vector of all the observations in the hierarchy at time $t$, $\bm{S}$ is the summing matrix as defined above, and $\bm{y}_{K,t}$ is a vector of all the observations in the bottom level of the hierarchy at time $t$. Note that the first row in the summing $\bm{S}$ represents equation \@ref(eq:toplevel) above, the second and third row represent \@ref(eq:middlelevel). The rows below these for an identity matrix so that each bottom level observation on the right hand side of the equation is equal to itself in the left hand side.

` I would like to add example here using hts`

```{r, eval=FALSE, include=FALSE, cache=TRUE}
abc <- ts(5 + matrix(sort(rnorm(1000)), ncol = 10, nrow = 100))
colnames(abc) <- c("A10A", "A10B", "A10C", "A20A", "A20B",
                   "B30A", "B30B", "B30C", "B40A", "B40B")

head(abc)
y <- hts(abc, characters = c(1, 2, 1))
head(y)
attributes(y)

```

## Grouped time series
Another possibility is that series can be naturally grouped together based on attributes without necessarily imposing a hierarchical structure. For example the bicycles sold by the warehouse can be for males, females or unisex. Frames can be carbon, aluminium or steel. They can be single speed or have multiple gears. We refer to these as *grouped time series*.

We can also get a similar effect when we combine two hierarchical structures. For example the bicycle manufacturer may disaggregate sales by product and also by geographical location. In this case we still have a hierarchical structure however the structure does not naturally disaggregate in a unique way. We can disaggregate by product type and then geographical location but also vice versa.
Figure \@ref(fig:GroupTree) below shows a $K=2$-level grouped structure. At the top of the structure hierarchy, is the "Total", the most aggregate level of the data, again represented by $y_t$. The "Total" can be disaggregated by attributes (A, B) forming series $\y{A}{t}$ and $\y{B}{t}$, or by attributes (X, Y) forming series $\y{X}{t}$ and $\y{Y}{t}$. At the bottom the data are disaggregated by both attributes.

```{r GroupTree, echo=FALSE, cache=TRUE, fig.cap="Alternative representations of a two level grouped structure.", out.width="49.9%", fig.show = "hold",fig.height=14,fig.width=12}

#,fig.width=20

g <- igraph::graph_from_literal(Total--A:B, A--AX:AY, B--BX:BY)
layout <- igraph::layout_as_tree(g, root = "Total")
igraph::V(g)$color <- c("Thistle", "GreenYellow", "LightBlue",
  rep("GreenYellow", 2), rep("LightBlue", 2))
igraph::V(g)$label.cex<-3.5
plot(g, layout = layout,vertex.size=44)

g2 <- igraph::graph_from_literal(Total--X:Y, X--AX:BX, Y--AY:BY)
layout2 <- igraph::layout_as_tree(g2, root = "Total")
igraph::V(g2)$color <- c("Thistle", "GreenYellow", "LightBlue",
  rep("GreenYellow", 2), rep("LightBlue", 2))
igraph::V(g2)$label.cex<-3.5
plot(g2, layout = layout,vertex.size=44)


```

This example shows that there are alternative aggregation paths for grouped structures. For any time $t$, as with the hierarchical structure,
\begin{equation*}
y_{t}=\y{AX}{t}+\y{AY}{t}+\y{BX}{t}+\y{BY}{t}.
\end{equation*}
However, for the first level of the grouped structure,
\begin{equation} \y{A}{t}=\y{AX}{t}+\y{AY}{t}\quad \quad \y{B}{t}=\y{BX}{t}+\y{BY}{t}
(\#eq:middlelevelAB)
\end{equation} but also
\begin{equation} \y{X}{t}=\y{AX}{t}+\y{BX}{t}\quad \quad \y{Y}{t}=\y{AY}{t}+\y{BY}{t}
(\#eq:middlelevelXY).
\end{equation}

These equalities can again be captured by the summing matrix $\bm{S}$ which recall is of dimension $n\times n_K$. The total number of series is $n=9$ with $n_K=4$ series at the bottom level. For the structure in Figure \@ref(fig:GroupTree) we write
$$
  \begin{bmatrix}
    y_{t} \\
    \y{A}{t} \\
    \y{B}{t} \\
    \y{X}{t} \\
    \y{Y}{t} \\
    \y{AX}{t} \\
    \y{AY}{t} \\
    \y{BX}{t} \\
    \y{BY}{t}
  \end{bmatrix}
  =
  \begin{bmatrix}
    1 & 1 & 1 & 1 \\
    1 & 1 & 0 & 0 \\
    0 & 0 & 1 & 1 \\
    1 & 0 & 1 & 0 \\
    0 & 1 & 0 & 1 \\
    1 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 \\
    0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 1
  \end{bmatrix}
  \begin{bmatrix}
    \y{AX}{t} \\
    \y{AY}{t} \\
    \y{BX}{t} \\
    \y{BY}{t}
  \end{bmatrix}
$$
where now the second and third rows of $\bm{S}$ represent \@ref(eq:middlelevelAB) and the fourth and fifth rows represent \@ref(eq:middlelevelXY).

Grouped time series can be thought of as hierarchical time series that do not impose a unique hierarchical structure in the sense that the order by which the series can be grouped is not unique.

## Base and revised forecasts

We are interested in generating forecasts for each series belonging to a hierarchical or a grouped structure. We denote as $\yhat{j}{h}$ the $h$-step-ahead forecast generated for the series at node $j$ having observed the time series up to observation $T$ and as $\hat{y}_{h}$ the $h$-step-ahead forecast generated for the "Total" series.^[We have simplified the previously used notation of $\hat{y}_{T+h|T}$ for brevity.] We refer to these as *base forecasts*. They are independent forecasts generated for the a series in the hierarchical or grouped structure using a suitable forecasting method presented in earlier sections of this book.

These base forecasts are then combined to produce forecasts for all the series that aggregate in a manner that is consistent with the hierarchical or grouped structure. We refer to these as *revised forecasts* and denote them as $\ytilde{j}{h}$ and $\tilde{y}_{h}$ respectively. There are a number of ways of combining base forecasts in order to obtain revised forecasts. The following sections discuss some of the possible combining approaches that can be used for forecasting time series data that possess hierarchical or grouped structures.

## The bottom-up approach

A commonly applied method is the bottom-up approach. This approach involves first generating independent base forecasts for each series at the bottom level. Then aggregating these upwards to produce forecasts for all the series in the structure.

For example, for the hierarchy of Figure \@ref(fig:HierTree) we first generate $h$-step-ahead base forecasts for each of the bottom level series: $$\yhat{AA}{h},~~\yhat{AB}{h},~~\yhat{AC}{h},~~ \yhat{BA}{h}~~\text{and}~~\yhat{BB}{h}.$$

Aggregating these up the hierarchy we get $h$-step-ahead revised forecasts for the rest of the series:  $$\tilde{y}_{h}=\yhat{AA}{h}+\yhat{AB}{h}+\yhat{AC}{h}+\yhat{BA}{h}+\yhat{BB}{h},~~~\ytilde{A}{h}= \yhat{AA}{h}+\yhat{AB}{h}+\yhat{AC}{h}~~~\text{and}~~~\ytilde{B}{h}= \yhat{BA}{h}+\yhat{BB}{h}.$$
As we did with the data itself we can employ the summing matrix here and write
$$
  \tilde{\bm{y}}_{h}=\bm{S}\hat{\bm{y}}_{K,h}.
$$
where $\bm{\tilde{y}}_{h}$ is a set of revised forecasts for the whole of the hierarchy stacked in the same way as the data.

The greatest advantage of this approach is that we are forecasting at the bottom level of a structure and therefore no information is lost due to aggregation. On the other hand bottom level data can be quite noisy and more challenging to model and forecast.

Note that for the bottom-up approach the revised forecasts for the bottom level series are equal to the base forecasts, i.e., $\tilde{\bm{y}}_{K,t}=\hat{\bm{y}}_{K,t}$.

## Top-down approaches

Top-down approaches involve first generating forecasts for the "Total" series $y_t$ on the top of the hierarchy and then disaggregating these downwards. We let $p_1,\dots,p_{n_K}$ be a set of proportions which dictate how the base forecasts of the "Total" series are to be distributed to revised forecasts for each series at the bottom level of the hierarchy. For example for the hierarchy of Figure \@ref(fig:HierTree) 
$$
  \ytilde{AA}{t}=p_1\hat{y}_t,~~~\ytilde{AB}{t}=p_2\hat{y}_t,~~~\ytilde{AC}{t}=p_3\hat{y}_t,~~~\ytilde{BA}{t}=p_4\hat{y}_t~~~\text{and}~~~~~~\ytilde{BB}{t}=p_5\hat{y}_t.
$$
Using matrix notation we can stack the set of proportions in a $n_K$-dimensional column vector $\bm{p}=(p_1,\ldots,p_{n_K})'$ and write
$$\tilde{\bm{y}}_{K,t}=\bm{p}\hat{y}_t$$
Once the bottom level forecasts have been generated we can aggregate these up the hierarchy to generate revised forecasts for the rest of the series. Using the summing matrix we can in general write for top-down approaches,
$$\tilde{\bm{y}}_h=\bm{S}\bm{p}\hat{y}_t.$$
Note that for all top-down approaches the top level revised forecasts are equal to the top level base forecasts, i.e., $\tilde{y}_{h}=\hat{y}_{h}$.

The most common top-down approaches specify proportions based on the historical proportions of the data. The two most common versions follow.

### Average historical proportions {-}

$$
  p_j=\frac{1}{T}\sum_{t=1}^{T}\frac{y_{j,t}}{{y_t}}
$$
for $j=1,\dots,n_K$. Each proportion $p_j$ reflects the average of the historical proportions of the bottom level series $y_{j,t}$ over the period $t=1,\dots,T$ relative to the Total aggregate $y_t$.

### Proportions of the historical averages {-}

$$
  p_j={\sum_{t=1}^{T}\frac{y_{j,t}}{T}}\Big/{\sum_{t=1}^{T}\frac{y_t}{T}}
$$
for $j=1,\dots,n_K$. Each proportion $p_j$ captures the average historical value of the bottom level series $y_{j,t}$ relative to the average value of the Total aggregate $y_t$.

The greatest attribute of such top-down approaches is their simplicity to apply. One only needs to model and generate forecasts for the most aggregated top level series. In general these approaches seem to produce quite reliable forecasts for the aggregate levels and they are very useful with low count data. On the other hand, their greatest disadvantage is the loss of information due to aggregation. With these top-down approaches, we are unable to capture and take advantage of individual series characteristics such as time dynamics, special events, etc.

In the example on forecasting Australian domestic tourism demand that follows, the data are highly seasonal. The seasonal pattern of tourist arrivals may vary across series depending on the tourism destination. An area with beaches as its main tourist attractions will have a very different seasonal pattern to an area with skiing as its main tourist attraction. This will not be captured by disaggregating the Total of these destinations based on historical proportions. Finally, with these methods the disaggregation of the "Total" series forecasts depends on historical and static proportions, and these proportions may be distorted by trends in the data.

### Forecast proportions {-}

An alternative approach that improves on the historical and static nature of the proportions specified above is to use forecast proportions.

To demonstrate the intuition of this method, consider a one level hierarchy. We first generate $h$-step-ahead base forecasts for all the series independently. At level 1 we calculate the proportion of each $h$-step-ahead base forecast to the aggregate of all the $h$-step-ahead base forecasts at this level. We refer to these as the forecast proportions and we use these to disaggregate the top level forecast and generate revised forecasts for the whole of the hierarchy.

For a $K$-level hierarchy this process is repeated for each node going from the top to the very bottom level. Applying this process leads to the following general rule for obtaining the forecast proportions
$$
  p_j=\prod^{K-1}_{\ell=0}\frac{\hat{y}_{j,h}^{(\ell)}}{\hat{S}_{j,h}^{(\ell+1)}}
$$
for $j=1,2,\dots,n_K$. These forecast proportions disaggregate the $h$-step-ahead base forecast of the "Total" series to $h$-step-ahead revised forecasts of the bottom level series. $\hat{y}_{j,h}^{(\ell)}$ is the $h$-step-ahead base forecast of the series that corresponds to the node which is $\ell$ levels above $j$. $\hat{S}_{j,h}^{(\ell)}$ is the sum of the $h$-step-ahead base forecasts below the node that is $\ell$ levels above node $j$ and are directly connected to that node.

We will use the hierarchy of Figure \@ref(fig:HierTree) to explain this notation and to demonstrate how this general rule is reached. Assume we have generated independent base forecasts for each series in the hierarchy. Remember that for the top level "Total" series, $\tilde{y}_{h}=\hat{y}_{h}$, for any top-down approach. Here are some examples using the above notation:

  * $\hat{y}_{\text{A},h}^{(1)}=\hat{y}_{\text{B},h}^{(1)}=\hat{y}_{h}= \tilde{y}_{h}$
  * $\hat{y}_{\text{AA},h}^{(1)}=\hat{y}_{\text{AB},h}^{(1)}=\hat{y}_{\text{AC},h}^{(1)}= \hat{y}_{\text{A},h}$
  * $\hat{y}_{\text{AA},h}^{(2)}=\hat{y}_{\text{AB},h}^{(2)}= \hat{y}_{\text{AC},h}^{(2)}=\hat{y}_{\text{BA},h}^{(2)}= \hat{y}_{\text{BB},h}^{(2)}=\hat{y}_{h}= \tilde{y}_{h}$
  * $\Shat{AA}{h}{1} = \Shat{AB}{h}{1}= \Shat{AC}{h}{1}= \yhat{AA}{h}+\yhat{AB}{h}+\yhat{AC}{h}$
  * $\Shat{AA}{h}{2} = \Shat{AB}{h}{2}= \Shat{AC}{h}{2}= \Shat{A}{h}{1} = \Shat{B}{h}{1}= \hat{S}_{h}= \yhat{A}{h}+\yhat{B}{h}$

Moving down the farthest left branch of the hierarchy the revised forecasts are given by
$$
  \ytilde{A}{h} = \Bigg(\frac{\yhat{A}{h}}{\Shat{A}{h}{1}}\Bigg) \tilde{y}_{h} =
  \Bigg(\frac{\yhat{AA}{h}^{(1)}}{\Shat{AA}{h}{2}}\Bigg) \tilde{y}_{h}
$$
and
$$
  \ytilde{AA}{h} = \Bigg(\frac{\yhat{AA}{h}}{\Shat{AA}{h}{1}}\Bigg) \ytilde{A}{h}
  =\Bigg(\frac{\yhat{AA}{h}}{\Shat{AA}{h}{1}}\Bigg) \Bigg(\frac{\yhat{AA}{h}^{(1)}}{\Shat{AA}{h}{2}}\Bigg)\tilde{y}_{h}.
$$
Consequently,
$$
  p_1=\Bigg(\frac{\yhat{AA}{h}}{\Shat{AA}{h}{1}}\Bigg) \Bigg(\frac{\yhat{AA}{h}^{(1)}}{\Shat{AA}{h}{2}}\Bigg)
$$
The other proportions can be similarly obtained. The greatest disadvantage of the top-down forecast proportions approach, which is a disadvantage of any top-down approach, is that they do not produce unbiased revised forecasts even if the base forecasts are unbiased.

## Middle-out approach

The middle-out approach combines bottom-up and top-down approaches. First the "middle level" is chosen and base forecasts are generated for all the series of this level and the ones below. For the series above the middle level, revised forecasts are generated using the bottom-up approach by aggregating the "middle-level" base forecasts upwards. For the series below the "middle level", revised forecasts are generated using a top-down approach by disaggregating the "middle level" base forecasts downwards.

## Optimal combination forecasts

Denote as $\bm{\hat{y}}_h$ a set of $h$-step ahead base forecasts generated independently for each series in a structure and stacked the same way as the data. For example for the hierarchy of Figure \@ref(fig:HierTree)
$$
\bm{\hat{y}}_h=\begin{bmatrix}
    \hat{y}_h \\
    \yhat{A}{h} \\
    \yhat{B}{h} \\
    \yhat{AA}{h} \\
    \yhat{AB}{h} \\
    \yhat{AC}{h} \\
    \yhat{BA}{h} \\
    \yhat{BB}{h} \\
  \end{bmatrix}.
$$

Then in general all forecasting approaches for either hierarchical or grouped structures can be represented as
\begin{equation}
  \bm{\tilde{y}}_h=\bm{S}\bm{P}\bm{\hat{y}}_h
  (\#eq:SP)
\end{equation}
where reading from right to left, $\bm{\hat{y}}_h$ is the set of independent $h$-step ahead base forecasts as defined above, $\bm{P}$ is a matrix that projects the independent base forecasts into the bottom level, the summing matrix $\bm{S}$ sums these up the aggregation structure to produce a set of revised forecasts $\bm{\tilde{y}}_h$.

The $\bm{P}$ matrix is defined according to the approach implemented. For example if the bottom-up approach is used to forecast the hierarchy of Figure \@ref(fig:HierTree),
$$\bm{P}=
  \begin{bmatrix}
    0 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\
    0 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\
    0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\
    0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\
    0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\
  \end{bmatrix}.
  $$
Notice that the $\bm{P}$ comprises two partitions. The first three columns which zero out the independent base forecasts for the series above the bottom level and the $n_K$-dimensional identity matrix which picks only the independent base forecasts of the bottom level, to then be summed up the hierarchy by the $\bm{S}$ matrix.

If any of the top-down approaches were used then $$\bm{P}=
  \begin{bmatrix}
    p_1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
    p_2 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
    p_3 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
    p_4 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
    p_5 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
  \end{bmatrix},
  $$
so that the first column includes the set of proportions that distribute the independent base forecasts of the top level to the bottom level and the rest of the columns zero out the independent base forecasts below the very top level of aggregation.

For a middle out approach the $\bm{P}$ matrix will be a combination of the above two. Using a set of proportions, the independent base forecasts of some pre-chosen level will be disaggregated to the bottom level to then be summed up the hierarchy with the summing matrix, with all other independent base forecasts being zeroed out.

All the approaches we have considered so far in this chapter involve choosing a particular level in the aggregation structure, generating independent base forecasts for this level, and then either aggregating up or disaggregating down these base forecasts to generate revised forecasts for the rest of the series. The above examples clearly reflect this through the $\bm{P}$ matrix.

In this section we introduce an approach that instead involves generating independent base forecast for each series. As these base forecasts are independently generated they will not add up according to the hierarchical or grouped structure, i.e., they will not be "aggregate consistent". The base forecasts are then combined to generate a set of revised forecasts that are as close as possible to the base forecasts but also aggregate consistently with the structure.

The general idea is derived from wanting to find a $\bm{P}$ matrix that minimises the forecast error of the revised forecasts from forecasting each time series in the structure. In what follows we present a simplified summary of the approach. There are a few necessary steps that need to be followed in order to get a good flavour of the approach. These unfortunately complicate the presentation. However following through these steps we get to the specification of $\bm{P}$ in equation \@ref(eq:MinT) which is labelled the **MinT** estimator as it **Min**imises the **T**race of the forecast errors of the revised forecasts across the whole structure. For further details and discussion please refer to @Mint.

Let $$\bm{e}_{T+h}=\bm{y}_{T+h}-\tilde{\bm{y}}_h$$ be the forecast errors after having produced a set of revised forecasts across the whole structure, stacked in the same order as the data. Note that this expression is a generalisation of a forecast error as defined in Section \@ref(accuracy) using matrix notation. It can be easily shown through Equation \@ref(eq:SP) above that for a set of independent base forecasts that are unbiased, which will be the case for all base forecasts generated using methods introduced in this book, using a $\bm{P}$ matrix such that $\bm{S}\bm{P}\bm{S}=\bm{S}$, generates a set of revised forecasts $\bm{\tilde{y}}_h$ that are also unbiased. Note that this will not hold for any top-down approach.^[TODO: See Exercise 10.1 - possibly set this as an exercise.]

@Mint show in Lemma 1 that
\begin{equation*}
\text{Var}[\bm{y}_{T+h}-\tilde{\bm{y}}_h]=\bm{S}\bm{P}\bm{W}_h\bm{P}'\bm{S}'
\end{equation*}
where $\bm{W}_h=E[(\bm{y}_{T+h}-\hat{\bm{y}}_h)(\bm{y}_{T+h}-\hat{\bm{y}}_h)']$ is the variance-covariance matrix of the $h-$step ahead base forecast errors. This is a very important result as it shows that the forecast error variance of the revised forecasts is a function of the error variance of base forecasts $\bm{W}_h$. The objective is to find a matrix $\bm{P}$ that minimises the error variance of the revised forecasts. @Mint show in Theorem 1 that the optimal matrix $\bm{P}$ that minimises the $tr[\bm{S}\bm{P}\bm{W}_h\bm{P}'\bm{S}']$ such that $\bm{S}\bm{P}\bm{S}=\bm{S}$ is given by
\begin{equation}
\bm{P}=(\bm{S}'\bm{W}_h^{-1}\bm{S})^{-1}\bm{S}'\bm{W}_h^{-1},
(\#eq:MinT)
\end{equation}
referred to as the MinT estimator, as explained above.

Note that the MinT estimator involves $\bm{W}_h$ the forecast error variance of the $h-$step ahead base forecasts. As this is challenging to estimate we provide below three simplifying specifications which have been shown to work well in both simulations and in practice.

1. Set $\bm{W}_h=k_h\bm{I}$ $\forall h$ where $k_{h} > 0$. This is the most simplifying assumption to make. Note that in this case $\bm{P}$ is independent of the data and no further estimation is required. The disadvantage is however that this specification does not account for the differences in the scale between the levels of the structure which naturally exist due to aggregation. The two specifications that follow do account for this.

2. Set $\bm{W}_{h} = k_{h}\text{diag}(\hat{\bm{W}}_{1})$ $\forall h$ where $k_{h} > 0$ and
    \[
        \hat{\bm{W}}_{1} = \frac{1}{T}\sum_{t=1}^{T}\hat{\bm{e}}_{t}\hat{\bm{e}}_{t}'
    \]
where $\hat{\bm{e}}_{t}$ are the residuals of the model that generated the base forecasts as defined in Section \@ref(toolbox-resids). This specification scales the base forecasts using the variance of the residuals and it is therefore referred to as the *variance scaling* specification.

3. Set $\bm{W}_{h}=k_{h}\bm{\Lambda}$, $\forall h$ where $k_{h} > 0$ and $\bm{\Lambda}=\text{diag}(\bm{S}\bm{1})$ where $\bm{1}$ is a unit column vector of dimension $n$. This specification assumes that the bottom level base forecast errors each have variance $k_{h}$ and are uncorrelated between nodes. Hence each element of the diagonal $\bm{\Lambda}$ matrix contains the number of forecast error variances contributing to that aggregation level. This estimator only depends on the structure of the hierarchy or the grouped time series. Is is therefore referred to as the specification that applies *structural scaling*. Notice that the structural scaling assumes equivariant forecast errors only within levels of the structure and not across levels which is unrealistically assumed by the first specification. Furthermore, applying the structural scaling specification is particularly useful in cases where residuals are not available and therefore variance scaling cannot be applied. For example, in cases where the base forecasts are generated by judgemental forecasting introduced in Chapter \@ref(ch-judgmental).


In summary, unlike any other existing approach, the optimal combination forecasts are generated using all the information available within a hierarchical or a grouped structure. This is very important as particular aggregation levels or groupings may reveal features of the data that are of interest to the user and are important to be modelled. These features may be completely hidden or not easily identifiable at other levels. For example, consider a hierarchical structure reflecting the geographical division of a country into states, regions, down to a very fine grid of statistical local areas. There are significant differences between the seasonal patterns in the number of tourists visiting a state or a region that is mainly seen as a summer destination versus a state or a region that caters for winter activities. These differences will be smoothed at the country level due to aggregation and on the other hand it may be extremely challenging to identify at the very bottom level of a statistical local area due to noise. Another example for a grouped structure is the difference in the sales of clothes between genders. Such differences will be completely smoothed out at the very top level of aggregation considering total sales, or may be very challenging to identify due to noise at the very bottom level.

## The hts package

Hierarchical time series forecasting is implemented in the **hts** package in R.

The `hts` function creates a hierarchical time series. The required inputs are the bottom level time series observations, and information about the hierarchical structure. For example, the structure shown in Figure \@ref(fig:HierTree) is specified as follows:

```{r, cache=TRUE}
library(hts)
# vn is a time series matrix containing the bottom level series

y <- hts(vn, nodes=list(4,c(2,2,2,2)))
allf <- forecast(y, h=8)
plot(allf)

```

For a grouped but non-hierarchical time series, the `gts` function can be used. If there are more levels, the `g` argument should be a matrix where each row contains the grouping structure for each level.

Forecasts are obtained, as usual, with the `forecast` function. By default it produces forecasts using the optimal combination approach with ETS models used for the base forecasts. But other models and methods can be specified via the following arguments.

fmethod
:   The forecasting model to be used for the base forecasts. Possible values are `"ets"`, `"arima"` and `"rw"`.

method
:   The method used for reconciling the base forecasts. It can take the following values:

    comb
    :   Optimal combination forecasts;

    bu
    :   Bottom-up forecasts;

    mo
    :   Middle-out forecasts where the level used is specified by the `level` argument’

    tdgsa
    :   Top-down forecasts based on the average historical proportions (Gross-Sohl method A);@GS90

    tdgsf
    :   Top-down forecasts based on the proportion of historical averages (Gross-Sohl method F);

    tdfp
    :   Top-down forecasts using forecast proportions.

##Example: Australian tourism hierarchy

Australia is divided into eight geographical areas (some referred to as states and others as territories) with each one having its own government and some economic and administrative autonomy. Business planners and tourism authorities are interested in forecasts for the whole of Australia, the states and the territories, and also smaller regions. In this example we concentrate on quarterly domestic tourism demand, measured as the number of visitor nights Australians spend away from home, for the three largest states of Australia, namely Victoria (VIC), New South Wales (NSW), Queensland (QLD) and other. For each of these we consider visitor nights for each respective capital city, namely, Melbourne (MEL), Sydney (SYD) and Brisbane (BGC).^[For the purpose of this example we include with Brisbane, visitor nights at the Gold Coast, a coastal city and a major tourism attraction near Brisbane.] The hierarchical structure is shown in Figure \@ref(fig-9-4-Aust). The CAP category in the bottom level includes visitor nights in all other five capital cities of the remaining states and territories.

```
\@ref(fig-9-4-Aust)

=[ellipse,draw,inner sep=1pt] =[sibling distance=30mm,font=] =[sibling
distance=15mm,font=]

child <span>node <span>NSW</span> child <span>node
<span>SYD</span></span> child <span>node <span>Other</span></span>
</span> child <span>node <span>VIC</span> child <span>node
<span>MEL</span></span> child <span>node <span>Other</span></span>
</span> child <span>node <span>QLD</span> child <span>node
<span>BGC</span></span> child <span>node <span>Other</span></span>
</span> child <span>node <span>Other</span> child <span>node
<span>CAP</span></span> child <span>node <span>Other</span></span>
</span>;
```

Figure \@ref(fig-9-4-forecasts) shows all the times series in the hierarchy which span the period 1998:Q1 to 2011:Q4. The dotted lines show the revised forecasts generated by the optimal combination approach. The base forecasts for each series are generated using the ETS methodology of Chapter \@ref(ch-expsmooth).

```{r htstourism, fig.cap="Hierarchical time series and 8-step-ahead revised forecasts for Australian domestic tourism generated by the optimal combination approach. The base forecasts for each series were generated using the ETS methodology of Chapter ??.", fig.height=6, cache=TRUE}
require(hts)
y <- hts(vn, nodes=list(4,c(2,2,2,2)))
allf <- forecast(y, h=8)
plot(allf)
```
